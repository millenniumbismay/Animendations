{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYmRZK_5aWzI"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import argparse\n",
        "from pdb import set_trace as bp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_data_path = \"preprocessed_animes.csv\"\n",
        "profiles_data_path = \"preprocessed_profiles.csv\"\n",
        "reviews_data_path = \"preprocessed_reviews.csv\"\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--option', default='1')\n",
        "args = parser.parse_args()\n",
        "selected_option = int(args.option)"
      ],
      "metadata": {
        "id": "0q9_fjbcadDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(selected_option!=1):\n",
        "  animes = pd.read_csv(animes_data_path)\n",
        "  profiles = pd.read_csv(profiles_data_path)\n",
        "  reviews = pd.read_csv(reviews_data_path, engine='python', sep=',', error_bad_lines=False)\n",
        "\n",
        "  anime_title_names = animes[\"title\"].to_numpy()\n",
        "  anime_title_names = np.array([x.replace(\" \", \"_\") for x in anime_title_names])\n",
        "  img_urls = animes[\"img_url\"].to_numpy()\n",
        "  with open('anime_title_names.pickle', 'wb') as handle:\n",
        "      pickle.dump(anime_title_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('img_urls.pickle', 'wb') as handle:\n",
        "      pickle.dump(img_urls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\n",
        "  failed_titles = []\n",
        "  no_urls = []\n",
        "  for i in range(len(anime_title_names)):\n",
        "    url = img_urls[i]\n",
        "    title = anime_title_names[i]\n",
        "    title = title.replace(\"/\", \"__\") \n",
        "    if not isinstance(url, str):\n",
        "      print(f\"Index = {i} and Url not there for Title: {title}\")\n",
        "      no_urls.append(i)\n",
        "      continue\n",
        "    title = title+ \".\" + url.split(\".\")[-1]\n",
        "    if(i%500==0):\n",
        "      print(i)\n",
        "    try:\n",
        "      PIL.Image.open(io.BytesIO(urllib.request.urlopen(url).read())).save(title)\n",
        "    except:\n",
        "      failed_titles.append(i)\n",
        "      print(f\"Failed at Index = {i} for Title: {title}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(\"failed_titles\\n\")\n",
        "  print(failed_titles)\n",
        "\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(\"no_urls\\n\")\n",
        "  print(no_urls)\n",
        "\n",
        "else:\n",
        "\n",
        "  animes = pd.read_csv(animes_data_path)\n",
        "  profiles = pd.read_csv(profiles_data_path)\n",
        "  reviews = pd.read_csv(reviews_data_path, engine='python', sep=',', error_bad_lines=False)\n",
        "\n",
        "  anime_uid_names = animes[\"uid\"].to_numpy()\n",
        "  img_urls = animes[\"img_url\"].to_numpy()\n",
        "  with open('anime_uid_names.pickle', 'wb') as handle:\n",
        "      pickle.dump(anime_uid_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('img_urls.pickle', 'wb') as handle:\n",
        "      pickle.dump(img_urls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\n",
        "  failed_titles = []\n",
        "  no_urls = []\n",
        "  for i in range(len(anime_uid_names)):\n",
        "    url = img_urls[i]\n",
        "    title = anime_uid_names[i]\n",
        "    if not isinstance(url, str):\n",
        "      print(f\"Index = {i} and Url not there for Title: {title}\")\n",
        "      no_urls.append(i)\n",
        "      continue\n",
        "    if(i%500==0):\n",
        "      print(i)\n",
        "    title = str(title) + '.jpg'\n",
        "    try:\n",
        "      PIL.Image.open(io.BytesIO(urllib.request.urlopen(url).read())).save(title)\n",
        "    except:\n",
        "      failed_titles.append(i)\n",
        "      print(f\"Failed at Index = {i} for Title: {title}\")\n",
        "\n",
        "\n",
        "  print(\"failed_titles\\n\")\n",
        "  print(failed_titles)\n",
        "  print(\"\\n\")\n",
        "  print(\"no_urls\\n\")\n",
        "  print(no_urls)"
      ],
      "metadata": {
        "id": "ZW7k0bJlabl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}